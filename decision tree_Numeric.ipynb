{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTree With the Numerical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step              0\n",
      "type              0\n",
      "amount            0\n",
      "nameOrig          0\n",
      "oldbalanceOrg     0\n",
      "newbalanceOrig    0\n",
      "nameDest          0\n",
      "oldbalanceDest    0\n",
      "newbalanceDest    0\n",
      "isFraud           0\n",
      "isFlaggedFraud    0\n",
      "dtype: int64\n",
      "Accuracy: 0.9970\n",
      "Precision: 0.9960\n",
      "Recall: 0.9981\n",
      "F1-score: 0.9971\n",
      "\n",
      "isFraud Confusion Matrix:\n",
      "[[1265735    5102]\n",
      " [   2403 1268523]]\n",
      "\n",
      "Number of Fraud Activities: 8213\n",
      "\n",
      "isFlaggedFraud Confusion Matrix:\n",
      "[[4668498   20552]\n",
      " [1661560   12010]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Define categorical columns\n",
    "    categorical_cols = [\"type\"]\n",
    "    numerical_cols = [col for col in data.columns if col not in categorical_cols + [\"isFraud\", \"nameOrig\", \"nameDest\", \"isFlaggedFraud\"]]\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = StandardScaler()\n",
    "\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    \n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    data_preprocessed = pipeline.fit_transform(data.drop(['isFraud', 'nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1))\n",
    "    return data_preprocessed, pipeline\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'max_depth': [4, 8, 12],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)  # Use all threads\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def main():\n",
    "    data = pd.read_csv(\"archive/PS_20174392719_1491204439457_log.csv\")\n",
    "\n",
    "    # Check for missing values (if applicable)\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    data_preprocessed, pipeline = preprocess_data(data.copy())  # Avoid modifying original data\n",
    "\n",
    "    # Handle class imbalance\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(data_preprocessed, data[\"isFraud\"])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model with hyperparameter tuning\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, precision, recall, f1 = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix for isFraud\n",
    "    y_pred = model.predict(X_test)\n",
    "    isfraud_cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nisFraud Confusion Matrix:\")\n",
    "    print(isfraud_cm)\n",
    "\n",
    "    # Count number of fraud activities\n",
    "    fraud_count = data[\"isFraud\"].sum()\n",
    "    print(f\"\\nNumber of Fraud Activities: {fraud_count}\")\n",
    "\n",
    "    # Confusion matrix for isFlaggedFraud (assuming a threshold of 200,000 for flagging)\n",
    "    data[\"isFlaggedFraud\"] = (data[\"amount\"] > 200000).astype(int)\n",
    "    \n",
    "    # Preprocess the data for isFlaggedFraud using the same pipeline\n",
    "    data_flagged_preprocessed = pipeline.transform(data.drop([\"isFlaggedFraud\", \"nameOrig\", \"nameDest\"], axis=1))\n",
    "    \n",
    "    flaggedfraud_cm = confusion_matrix(data[\"isFlaggedFraud\"], model.predict(data_flagged_preprocessed))\n",
    "    print(\"\\nisFlaggedFraud Confusion Matrix:\")\n",
    "    print(flaggedfraud_cm)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
